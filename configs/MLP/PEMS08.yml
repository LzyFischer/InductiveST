if_grad_aug: False
aug_model_name: "CG"
model_name: "MLP"
epochs: 100
window_size: &window_size 24
horizon: &horizon 12 # output size
lr: 0.002
weight_decay: 0.0001
milestones: [1, 50, 100]
gamma: 0.5
save_dir: "./ckpts"
model_file: "model_92.84308624267578.pt"
tolerance: 10 # now running like without early stopping
batch_size: 16 # hyper
device: &device "cuda"
data_root: "/home/zhenyu/program/TSF/framework/BasicTS/datasets/raw_data/PEMS08/"
processed_root: "/home/zhenyu/program/TSF/framework/InductiveST/data/"
dataset_name: "PEMS08"
values_name: "PEMS08.npz"
networks_name: &networks_name "adj_PEMS08.pkl"
optimizer: "Adam"
input_size: &input_size 3 # 1 for univariate, 2 for multivariate
dropout: 0
mode: "train"
split_ratio: [0.6, 0.2, 0.2]
num_nodes: &num_nodes 170

##### for metrics 
full_metrics: True

##### for training setting
train_normalized: False
dropout: 0
optimizer: "Adam"
gamma: 0.5
milestones: [1, 50, 100]
batch_size: 16 # hyper
lr: 0.002
weight_decay: 0.0001
epochs: 100
mask_node_loss: False
mask_node_ratio: 0.5
drop_node: False
drop_node_ratio: 0.1

##### for inductive task setting
train_node_ratio: 0.1
val_node_ratio: 0
seed: 0

##### for dicrepancy
balanced_loss: False
embedding_loss: False

#### VAE
is_vae: False
vae_epochs: 0
vae:
  input_dim: *input_size
  hidden_dim: 64
  latent_dim: 64
  num_layers: 2
  dropout: 0.1

##### for mixup
anchor_lambda: 0.5

##### for graph augmentation methods mainly
graph_learning: False
dynamic_graph: False
graph:
  hidden_dim: 64
  node2edge_type: cosine
sparse_threshold: 0.6
random_graph: False
gumbel_softmax: True
gumbel_tau: 1

##### decomposition (still working)
rstl: True

##### model 
batch_norm: False
model:
  hidden_dim: 64
  prediction_seq_len: *horizon
  window_size: *window_size

##### augmentation
aug_node: True
aug_model:
  input_dim: *input_size
  hidden_dim: 64
  latent_dim: 64
  num_layers: 2
  dropout: 0.1


##### wandb
wandb: True
wandb_project: "InductiveST"
wandb_name: [model_name, dataset_name, dynamic_graph, vae_loss_weight, vae.variance, sparse_threshold, lr, weight_decay]